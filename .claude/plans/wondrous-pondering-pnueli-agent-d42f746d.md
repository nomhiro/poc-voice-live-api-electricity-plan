# Implementation Plan: Conversation Summary Email Feature

## Overview

After the AI agent completes all customer requests during a voice conversation, the agent should proactively call a tool to send an email containing:
1. A summary of the conversation (auto-generated by GPT-4.1)
2. The full conversation transcript (user and assistant messages only)

## Key Design Decision: How to Pass Transcript to the Tool

### The Challenge
The Azure OpenAI Realtime API agent does NOT automatically have access to conversation history when calling tools. The transcript is tracked client-side in React state (`app/realtime/page.tsx`).

### Solution: Frontend Transcript Injection

**Approach:** When the frontend executes the `send_conversation_email` function call, it will inject the current transcript into the request body before sending to the API endpoint.

This follows the existing pattern where the frontend already intercepts function calls and executes them:
```typescript
// From app/realtime/page.tsx - existing pattern
const fnRes = await fetch(`/api/functions/${encodeURIComponent(funcName)}`, {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify(args)
})
```

**Modified approach:**
```typescript
// When funcName === 'send_conversation_email'
// Inject transcript from React state before sending
const enrichedArgs = {
  ...args,
  transcript: transcripts.filter(t => t.speaker === 'user' || t.speaker === 'assistant')
}
```

## Implementation Details

### 1. New Tool Definition in Session Route

**File:** `app/api/realtime/session/route.ts`

Add new tool to the `tools` array:
```typescript
{
  type: 'function',
  name: 'send_conversation_email',
  description: 'ä¼šè©±çµ‚äº†æ™‚ã«ã€ãŠå®¢æ§˜ã«ãƒ¡ãƒ¼ãƒ«ã§ä¼šè©±å†…å®¹ã®ã‚µãƒãƒªãƒ¼ã¨å…¨æ–‡ã‚’é€ä¿¡ã—ã¾ã™ã€‚æœ¬äººç¢ºèªæ¸ˆã¿ã®ãŠå®¢æ§˜ã«ã®ã¿é€ä¿¡å¯èƒ½ã§ã™ã€‚ãŠå®¢æ§˜ãŒå…¨ã¦ã®è¦ä»¶ã‚’å®Œäº†ã—ã€ã€Œä»–ã«ã”ä¸æ˜ãªç‚¹ã¯ã”ã–ã„ã¾ã™ã‹ï¼Ÿã€ã«å¯¾ã—ã¦ã€Œãªã„ã€ã¨å›ç­”ã—ãŸå ´åˆã«å‘¼ã³å‡ºã—ã¦ãã ã•ã„ã€‚',
  parameters: {
    type: 'object',
    properties: {
      customerId: {
        type: 'string',
        description: 'æœ¬äººç¢ºèªæ¸ˆã¿ã®é¡§å®¢ID'
      },
      customerEmail: {
        type: 'string',
        description: 'ãŠå®¢æ§˜ã®ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ï¼ˆget_customer_infoã§å–å¾—æ¸ˆã¿ï¼‰'
      },
      customerName: {
        type: 'string',
        description: 'ãŠå®¢æ§˜ã®ãŠåå‰'
      }
    },
    required: ['customerId', 'customerEmail', 'customerName']
  }
}
```

### 2. Update AI Agent Instructions

**File:** `app/api/realtime/session/route.ts`

Add to the `instructions` string:
```
# ä¼šè©±çµ‚äº†æ™‚ã®ãƒ¡ãƒ¼ãƒ«é€ä¿¡ãƒ«ãƒ¼ãƒ«
- ãŠå®¢æ§˜ãŒå…¨ã¦ã®ç”¨ä»¶ã‚’å®Œäº†ã—ã€ã€Œä»–ã«ã”ä¸æ˜ãªç‚¹ã¯ã”ã–ã„ã¾ã™ã‹ï¼Ÿã€ã«å¯¾ã—ã¦ã€Œãªã„ã€ã¾ãŸã¯ã€Œå¤§ä¸ˆå¤«ã§ã™ã€ã¨å›ç­”ã—ãŸå ´åˆ
- æœ¬äººç¢ºèªæ¸ˆã¿ï¼ˆget_customer_info ãŒæˆåŠŸã—ã¦ã„ã‚‹ï¼‰ã®ãŠå®¢æ§˜ã«å¯¾ã—ã¦ã€ä¼šè©±ã®ã‚µãƒãƒªãƒ¼ãƒ¡ãƒ¼ãƒ«ã‚’é€ä¿¡ã™ã‚‹
- send_conversation_email ãƒ„ãƒ¼ãƒ«ã‚’å‘¼ã³å‡ºã™å‰ã«ã€Œãã‚Œã§ã¯ã€æœ¬æ—¥ã®ä¼šè©±å†…å®¹ã‚’ãƒ¡ãƒ¼ãƒ«ã§ãŠé€ã‚Šã—ã¾ã™ã­ã€ã¨ä¼ãˆã‚‹
- ãƒ¡ãƒ¼ãƒ«é€ä¿¡å¾Œã€ã€Œãƒ¡ãƒ¼ãƒ«ã‚’ãŠé€ã‚Šã—ã¾ã—ãŸã€‚ãŠé›»è©±ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€ã§ç· ã‚ã‚‹
```

### 3. New API Endpoint

**File:** `app/api/functions/send_conversation_email/route.ts`

```typescript
import { NextRequest, NextResponse } from 'next/server';
import { getEmailTransporter } from '@/lib/emailClient';
import { AzureOpenAI } from 'openai';
import type { ErrorResponse } from '@/lib/types/electricity';

interface TranscriptMessage {
  id: string;
  speaker: 'user' | 'assistant';
  text: string;
  partial?: boolean;
}

interface RequestBody {
  customerId?: string;
  customerEmail?: string;
  customerName?: string;
  transcript?: TranscriptMessage[];  // Injected by frontend
}

async function generateSummary(transcript: TranscriptMessage[]): Promise<string> {
  const endpoint = process.env.AZURE_OPENAI_ENDPOINT;
  const apiKey = process.env.AZURE_OPENAI_API_KEY;
  
  if (!endpoint || !apiKey) {
    return 'ï¼ˆã‚µãƒãƒªãƒ¼ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸï¼‰';
  }

  // Format transcript for GPT
  const conversationText = transcript
    .filter(t => !t.partial)
    .map(t => `${t.speaker === 'user' ? 'ãŠå®¢æ§˜' : 'ã‚ªãƒšãƒ¬ãƒ¼ã‚¿ãƒ¼'}: ${t.text}`)
    .join('\n');

  try {
    const client = new AzureOpenAI({
      endpoint,
      apiKey,
      apiVersion: '2024-08-01-preview'
    });

    const response = await client.chat.completions.create({
      model: process.env.AZURE_OPENAI_CHAT_DEPLOYMENT || 'gpt-4.1',
      messages: [
        {
          role: 'system',
          content: `ã‚ãªãŸã¯é›»åŠ›ä¼šç¤¾ã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒãƒ¼ãƒˆã®ä¼šè©±ã‚’ã¾ã¨ã‚ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã®ä¼šè©±å†…å®¹ã‚’ç°¡æ½”ã«è¦ç´„ã—ã¦ãã ã•ã„ã€‚
- ãŠå®¢æ§˜ã®ãŠå•ã„åˆã‚ã›å†…å®¹
- å¯¾å¿œçµæœï¼ˆç¢ºèªã—ãŸæƒ…å ±ã€æ‰‹ç¶šãã®æœ‰ç„¡ãªã©ï¼‰
- ä»Šå¾Œã®å¯¾å¿œäº‹é …ãŒã‚ã‚Œã°è¨˜è¼‰
ç®‡æ¡æ›¸ãã§3ã€œ5é …ç›®ç¨‹åº¦ã«ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚`
        },
        {
          role: 'user',
          content: conversationText
        }
      ],
      max_tokens: 500,
      temperature: 0.3
    });

    return response.choices[0]?.message?.content || 'ï¼ˆã‚µãƒãƒªãƒ¼ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸï¼‰';
  } catch (error) {
    console.error('Summary generation failed:', error);
    return 'ï¼ˆã‚µãƒãƒªãƒ¼ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸï¼‰';
  }
}

export async function POST(request: NextRequest) {
  try {
    const body: RequestBody = await request.json();
    const { customerId, customerEmail, customerName, transcript } = body;

    // Validation
    if (!customerId || !customerEmail || !customerName) {
      const errorResponse: ErrorResponse = {
        success: false,
        error: 'ãƒ¡ãƒ¼ãƒ«é€ä¿¡ã«å¿…è¦ãªæƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚',
        errorCode: 'INVALID_INPUT'
      };
      return NextResponse.json(errorResponse, { status: 400 });
    }

    if (!transcript || transcript.length === 0) {
      const errorResponse: ErrorResponse = {
        success: false,
        error: 'ä¼šè©±å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“ã€‚',
        errorCode: 'INVALID_INPUT'
      };
      return NextResponse.json(errorResponse, { status: 400 });
    }

    const emailTransporter = getEmailTransporter();
    if (!emailTransporter) {
      // Email not configured - return success anyway for POC
      console.log('Email skipped: transporter not configured');
      return NextResponse.json({
        success: true,
        message: 'ãƒ¡ãƒ¼ãƒ«é€ä¿¡æ©Ÿèƒ½ã¯ç¾åœ¨è¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚',
        skipped: true
      });
    }

    // Generate summary using GPT-4.1
    const summary = await generateSummary(transcript);

    // Format transcript for email
    const transcriptHtml = transcript
      .filter(t => !t.partial)
      .map(t => `
        <div style="margin-bottom: 12px;">
          <strong style="color: ${t.speaker === 'user' ? '#0066cc' : '#333'};">
            ${t.speaker === 'user' ? 'ãŠå®¢æ§˜' : 'ã‚ªãƒšãƒ¬ãƒ¼ã‚¿ãƒ¼'}:
          </strong>
          <span>${t.text}</span>
        </div>
      `)
      .join('');

    const now = new Date();
    const dateStr = `${now.getFullYear()}å¹´${now.getMonth() + 1}æœˆ${now.getDate()}æ—¥ ${now.getHours()}:${String(now.getMinutes()).padStart(2, '0')}`;

    // Send email
    await emailTransporter.sendMail({
      from: process.env.GMAIL_USER,
      to: customerEmail,
      subject: `ã€é›»åŠ›ã‚µãƒãƒ¼ãƒˆã€‘ãŠå•ã„åˆã‚ã›å†…å®¹ã®ã”ç¢ºèªï¼ˆ${dateStr}ï¼‰`,
      html: `
        <div style="font-family: sans-serif; max-width: 600px; margin: 0 auto;">
          <h2 style="color: #333; border-bottom: 2px solid #0066cc; padding-bottom: 8px;">
            ãŠå•ã„åˆã‚ã›å†…å®¹ã®ã”ç¢ºèª
          </h2>
          
          <p>${customerName} æ§˜</p>
          <p>æœ¬æ—¥ã¯ãŠé›»è©±ã„ãŸã ãã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€‚<br>ãŠå•ã„åˆã‚ã›å†…å®¹ã‚’ä»¥ä¸‹ã«ã¾ã¨ã‚ã¾ã—ãŸã®ã§ã”ç¢ºèªãã ã•ã„ã€‚</p>
          
          <hr style="border: none; border-top: 1px solid #ddd; margin: 24px 0;">
          
          <h3 style="color: #0066cc;">ä¼šè©±ã®ã‚µãƒãƒªãƒ¼</h3>
          <div style="background: #f8f9fa; padding: 16px; border-radius: 8px; white-space: pre-wrap;">
${summary}
          </div>
          
          <hr style="border: none; border-top: 1px solid #ddd; margin: 24px 0;">
          
          <h3 style="color: #0066cc;">ä¼šè©±ã®å…¨æ–‡</h3>
          <div style="background: #fff; padding: 16px; border: 1px solid #e0e0e0; border-radius: 8px;">
            ${transcriptHtml}
          </div>
          
          <hr style="border: none; border-top: 1px solid #ddd; margin: 24px 0;">
          
          <p style="color: #666; font-size: 14px;">
            å†…å®¹ã«ã”ä¸æ˜ãªç‚¹ãŒã”ã–ã„ã¾ã—ãŸã‚‰ã€ãŠæ°—è»½ã«ãŠå•ã„åˆã‚ã›ãã ã•ã„ã€‚<br>
            ä»Šå¾Œã¨ã‚‚é›»åŠ›ã‚µãƒãƒ¼ãƒˆã‚’ã‚ˆã‚ã—ããŠé¡˜ã„ã„ãŸã—ã¾ã™ã€‚
          </p>
          
          <p style="margin-top: 24px;">æ ªå¼ä¼šç¤¾ é›»åŠ›ã‚µãƒãƒ¼ãƒˆ</p>
        </div>
      `
    });

    console.log(`Conversation email sent to ${customerEmail}`);

    return NextResponse.json({
      success: true,
      message: 'ãƒ¡ãƒ¼ãƒ«ã‚’é€ä¿¡ã—ã¾ã—ãŸã€‚',
      sentTo: customerEmail
    });

  } catch (error) {
    console.error('Error in send_conversation_email:', error);
    const errorResponse: ErrorResponse = {
      success: false,
      error: 'ãƒ¡ãƒ¼ãƒ«é€ä¿¡ã«å¤±æ•—ã—ã¾ã—ãŸã€‚',
      errorCode: 'SYSTEM_ERROR'
    };
    return NextResponse.json(errorResponse, { status: 500 });
  }
}

export async function GET() {
  return NextResponse.json({
    endpoint: 'send_conversation_email',
    description: 'ä¼šè©±çµ‚äº†æ™‚ã«ãŠå®¢æ§˜ã«ãƒ¡ãƒ¼ãƒ«ã§ä¼šè©±ã‚µãƒãƒªãƒ¼ã¨å…¨æ–‡ã‚’é€ä¿¡ã—ã¾ã™ã€‚',
    method: 'POST',
    parameters: {
      customerId: 'é¡§å®¢IDï¼ˆå¿…é ˆï¼‰',
      customerEmail: 'ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ï¼ˆå¿…é ˆï¼‰',
      customerName: 'ãŠå®¢æ§˜åï¼ˆå¿…é ˆï¼‰',
      transcript: 'ä¼šè©±å±¥æ­´ï¼ˆãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‹ã‚‰è‡ªå‹•æ³¨å…¥ï¼‰'
    }
  });
}
```

### 4. Frontend Modification

**File:** `app/realtime/page.tsx`

Modify the function call execution to inject transcript for `send_conversation_email`:

```typescript
// Inside the dc.onmessage handler, where function calls are executed
if (funcName && dc && (dc.readyState === 'open')) {
  // Special handling for send_conversation_email - inject transcript
  let enrichedArgs = args;
  if (funcName === 'send_conversation_email') {
    // Filter to only user and assistant messages, exclude partials
    const filteredTranscript = transcripts
      .filter(t => (t.speaker === 'user' || t.speaker === 'assistant') && !t.partial)
      .map(t => ({ id: t.id, speaker: t.speaker, text: t.text }));
    enrichedArgs = { ...args, transcript: filteredTranscript };
  }

  // é–¢æ•°å®Ÿè¡Œå‰ã«Input JSONã‚’è¡¨ç¤º
  const inputText = `ğŸ”§ ${funcName}: ${JSON.stringify(args, null, 2)}`;
  setTranscripts(prev => [...prev, { id: 'tool-input-' + String(Date.now()), speaker: 'tool', text: inputText, partial: false }]);

  // Call local function endpoint with enriched args
  try {
    const fnRes = await fetch(`/api/functions/${encodeURIComponent(funcName)}`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify(enrichedArgs)  // Use enrichedArgs instead of args
    });
    // ... rest of the handler
  }
}
```

**Note:** This modification needs to be applied in TWO places in the file:
1. In the `dc.onmessage` handler (main data channel)
2. In the `pc.ondatachannel` handler (server-initiated data channel)

### 5. Type Definition Addition

**File:** `lib/types/electricity.ts`

Add new response type:
```typescript
// send_conversation_email
export interface ConversationEmailResponse {
  success: true;
  message: string;
  sentTo?: string;
  skipped?: boolean;
}
```

### 6. Environment Variables

Add to `.env.local.example`:
```
# For GPT-4.1 summary generation (uses same Azure OpenAI resource)
AZURE_OPENAI_CHAT_DEPLOYMENT=gpt-4.1
```

## Files to Modify/Create

| File | Action | Description |
|------|--------|-------------|
| `app/api/realtime/session/route.ts` | Modify | Add tool definition and update instructions |
| `app/api/functions/send_conversation_email/route.ts` | Create | New API endpoint |
| `app/realtime/page.tsx` | Modify | Inject transcript for send_conversation_email |
| `lib/types/electricity.ts` | Modify | Add ConversationEmailResponse type |
| `.env.local.example` | Modify | Add AZURE_OPENAI_CHAT_DEPLOYMENT |

## Summary of Approach

1. **Tool Definition**: AI agent gets a new `send_conversation_email` tool with customerId, customerEmail, and customerName parameters
2. **Instructions**: AI knows when to call the tool (after user says no more questions)
3. **Frontend Injection**: Frontend automatically injects the transcript when executing this specific function
4. **API Endpoint**: Generates summary using GPT-4.1, formats email, and sends via existing Nodemailer setup
5. **Graceful Fallback**: If email is not configured, returns success with `skipped: true`

## Critical Files for Implementation

1. **`app/api/realtime/session/route.ts`** - Add tool definition and update AI instructions
2. **`app/api/functions/send_conversation_email/route.ts`** - New endpoint to create
3. **`app/realtime/page.tsx`** - Modify function call handler to inject transcript
4. **`lib/emailClient.ts`** - Reference for email sending pattern (no changes needed)
5. **`lib/types/electricity.ts`** - Add response type definition
